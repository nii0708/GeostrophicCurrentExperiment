{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yiNwzOeQ2Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2caef887-4cf8-49d0-889c-b4207475061c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data from google drive: https://drive.google.com/drive/folders/1ufRGISCS4hOSuJjpJ36ydkvxrTZ64Nlp?usp=drive_link"
      ],
      "metadata": {
        "id": "L8gboP56J1OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/paper/raw_data.pickle','rb') as r:\n",
        "    raw_data = pickle.load(r)"
      ],
      "metadata": {
        "id": "JgELhJJPQ75v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUiAqOzwQ2Gr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import date\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1SNbgjzQ2Gs"
      },
      "outputs": [],
      "source": [
        "def parse(date_string):\n",
        "    '''\n",
        "      Change date into list of integers\n",
        "    '''\n",
        "    return [int(i) for i in date_string.split('-')]\n",
        "\n",
        "def get_split_index(start_index,end_index,start_date,end_date):\n",
        "    '''\n",
        "    Calculate the start and end indices for a given date range.\n",
        "\n",
        "    Args:\n",
        "        start_index (str): The start date index in the format 'YYYY-MM-DD'.\n",
        "        end_index (str): The end date index in the format 'YYYY-MM-DD'.\n",
        "        start_date (str): The start date of the date range in the format 'YYYY-MM-DD'.\n",
        "        end_date (str): The end date of the date range in the format 'YYYY-MM-DD'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two integers:\n",
        "            - index_start (int): The number of days from the start_date to start_index.\n",
        "            - index_end (int): The number of days from the start_date to end_index, plus one.\n",
        "    '''\n",
        "    ys,ms,ds = parse(start_index)\n",
        "    ye,me,de = parse(end_index)\n",
        "    ysd,msd,dsd = parse(start_date)\n",
        "    yed,med,ded = parse(end_date)\n",
        "    start_time = date(ys,ms,ds)\n",
        "    end_time   = date(ye,me,de)\n",
        "    start_time_date = date(ysd,msd,dsd)\n",
        "    end_time_date   = date(yed,med,ded)\n",
        "    index_start = (start_time - start_time_date).days\n",
        "    index_end   = (end_time - start_time_date).days+1\n",
        "    if index_start < 0 or (end_time - end_time_date).days > 0 or end_time==start_time:\n",
        "        raise ValueError(f'index date invalid with condition {index_start} < 0 or {(end_time - end_time_date).days} > 0 or {end_time} == {start_time}')\n",
        "    return index_start,index_end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "template data for masking land data"
      ],
      "metadata": {
        "id": "iNbBZyynKDLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-hlDE5eQ2Gt"
      },
      "outputs": [],
      "source": [
        "template_data = torch.isnan(torch.cat([torch.tensor(np.array(raw_data['center'])),\n",
        "                                       torch.tensor(np.array(raw_data['north'])),\n",
        "                                       torch.tensor(np.array(raw_data['south'])),\n",
        "                                       torch.tensor(np.array(raw_data['west'])),\n",
        "                                       torch.tensor(np.array(raw_data['east'])),\n",
        "                                       torch.tensor(np.array(raw_data['u_geos'])),\n",
        "                                       torch.tensor(np.array(raw_data['v_geos']))])).any(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Ea-1wcQ2Gt"
      },
      "outputs": [],
      "source": [
        "class MLPDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 start_index_date,\n",
        "                 end_index_date,\n",
        "                 plot = False,\n",
        "                 number_out = 5,\n",
        "                 number_in = 1,\n",
        "                 mask = None,\n",
        "                 start_date=\"2013-01-01\",\n",
        "                 end_date=\"2021-12-31\"):\n",
        "        self.number_out = number_out\n",
        "        self.number_in = number_in\n",
        "        self.plot = plot\n",
        "        self.mask = mask\n",
        "        self.start_index_date = start_index_date\n",
        "        self.end_index_date   = end_index_date\n",
        "        self.start_date = start_date\n",
        "        self.end_date   = end_date\n",
        "        self.start, self.end  = get_split_index(self.start_index_date,self.end_index_date,self.start_date,self.end_date)\n",
        "        self.data = self.preprocess(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0][1,:])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x,y = self.data[0][:,index],self.data[1][:,index]\n",
        "        return x,y\n",
        "\n",
        "    def clean(self, x,y):\n",
        "        if self.mask is None:\n",
        "            x_mask = torch.isnan(x[:,:17745]).any(dim=0)\n",
        "            y_mask = torch.isnan(y[:,:17745]).any(dim=0)\n",
        "\n",
        "            self.mask = torch.logical_or(x_mask,y_mask)\n",
        "            # shape = int(x.shape[1]/17745)\n",
        "            # self.mask = mask.expand(shape,17745).flatten()\n",
        "        shape = int(x.shape[1]/17745)\n",
        "        self.mask = self.mask.reshape(1,17745).expand(shape,17745).flatten()\n",
        "        # Use masked_select to select non-NaN values along the desired axis\n",
        "        filtered_x = x[:, ~self.mask]\n",
        "        filtered_y = y[:, ~self.mask]\n",
        "        return filtered_x, filtered_y\n",
        "\n",
        "    def preprocess(self,data):\n",
        "        # X\n",
        "        # init x\n",
        "        lat     = []\n",
        "        lon     = []\n",
        "        center  = []\n",
        "        north   = []\n",
        "        south   = []\n",
        "        east    = []\n",
        "        west    = []\n",
        "        u_in    = []\n",
        "        v_in    = []\n",
        "\n",
        "        # iterate over days\n",
        "        lat.append(torch.tensor(np.roll(data['lat'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],self.number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "        lon.append(torch.tensor(np.roll(data['lon'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],self.number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "        for number_in in range(self.number_in):\n",
        "            center.append(torch.tensor(np.roll(data['center'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            north.append(torch.tensor(np.roll(data['north'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            south.append(torch.tensor(np.roll(data['south'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            east.append(torch.tensor(np.roll(data['east'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            west.append(torch.tensor(np.roll(data['west'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "\n",
        "            u_in.append(torch.tensor(np.roll(data['u_geos'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            v_in.append(torch.tensor(np.roll(data['v_geos'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],number_in,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "        #join days\n",
        "        lat     = torch.cat(lat)\n",
        "        lon     = torch.cat(lon)\n",
        "        center  = torch.cat(center)\n",
        "        north   = torch.cat(north)\n",
        "        south   = torch.cat(south)\n",
        "        east    = torch.cat(east)\n",
        "        west    = torch.cat(west)\n",
        "        u_in    = torch.cat(u_in)\n",
        "        v_in    = torch.cat(v_in)\n",
        "\n",
        "        X = torch.cat([lat,lon,center,north,south,east,west,u_in,v_in])\n",
        "\n",
        "        # Y\n",
        "        # init y\n",
        "        u_out = []\n",
        "        v_out = []\n",
        "\n",
        "        # iterate over days\n",
        "        for number_out in range(1,1+self.number_out):\n",
        "            u_out.append(torch.tensor(np.roll(data['u_geos'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],-number_out,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "            v_out.append(torch.tensor(np.roll(data['v_geos'][max(0,self.start-self.number_in+1):min(self.end+self.number_out,3287)],-number_out,axis=0), dtype=torch.float32)[self.number_in-1:-self.number_out,:,:].reshape(1,-1))\n",
        "        #join days\n",
        "        u_out = torch.cat(u_out)\n",
        "        v_out = torch.cat(v_out)\n",
        "        Y = torch.cat([u_out,v_out])\n",
        "\n",
        "        if not self.plot:\n",
        "            X,Y = self.clean(X,Y)\n",
        "        return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVNu7pJJQ2Gu"
      },
      "outputs": [],
      "source": [
        "train_data = MLPDataset(raw_data,\"2013-01-01\",\"2018-12-31\", number_out = 5, number_in = 7, mask = template_data)\n",
        "test_data  = MLPDataset(raw_data,\"2019-01-01\",\"2021-12-31\", number_out = 5, number_in = 7, mask = template_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DifferenceLoss(nn.Module):\n",
        "    def __init__(self, epsilon=0.001):\n",
        "        \"\"\"\n",
        "        Initialize the loss function.\n",
        "\n",
        "        Args:\n",
        "            alpha (float): The weight given to L1 loss. (1 - alpha) will be the weight for L2 loss.\n",
        "        \"\"\"\n",
        "        super(DifferenceLoss, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        \"\"\"\n",
        "        Calculate the combined L1 and L2 loss.\n",
        "\n",
        "        Args:\n",
        "            outputs (torch.Tensor): The predictions of the model.\n",
        "            targets (torch.Tensor): The actual values.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The calculated loss.\n",
        "        \"\"\"\n",
        "        num_examples = outputs.size()[0]\n",
        "        true = targets.reshape(num_examples,-1)\n",
        "        pred = outputs.reshape(num_examples,-1)\n",
        "        reconstruction_error= torch.sum(torch.pow((pred-true),2,),dim=1)\n",
        "\n",
        "        true_diff = torch.diff(true.view(num_examples,2,-1)).view(num_examples,-1)\n",
        "        pred_diff = torch.diff(pred.view(num_examples,2,-1)).view(num_examples,-1)\n",
        "        difference_error    = torch.sum(torch.pow((pred_diff-true_diff),2),dim=1)\n",
        "\n",
        "        combined_loss = torch.mean(difference_error+reconstruction_error)\n",
        "        return combined_loss\n",
        "\n",
        "from numpy import linalg as LA\n",
        "def MSE(outputs, targets):\n",
        "  \"\"\"\n",
        "  Calculate the combined L1 and L2 loss.\n",
        "\n",
        "  Args:\n",
        "    outputs (torch.Tensor): The predictions of the model.\n",
        "    targets (torch.Tensor): The actual values.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The calculated loss.\n",
        "  \"\"\"\n",
        "  num_examples = outputs.shape[0]\n",
        "  true = targets.reshape(num_examples,-1)\n",
        "  pred = outputs.reshape(num_examples,-1)\n",
        "  reconstruction_error = np.mean(np.power((pred-true),2))\n",
        "  return reconstruction_error"
      ],
      "metadata": {
        "id": "qDkwq8c9ne6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=100,\n",
        "    shuffle=True,\n",
        "    #collate_fn=custom_collate_fn  # Pass your custom collate function if needed\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=100,\n",
        "    shuffle=True,\n",
        "    #collate_fn=custom_collate_fn  # Pass your custom collate function if needed\n",
        ")"
      ],
      "metadata": {
        "id": "y7Ujykt6XhG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TnYSf8sQ2Gv"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,num_input,num_output):\n",
        "        super(MLP, self).__init__()\n",
        "        # Define the first fully connected layer\n",
        "        self.fc1 = nn.Linear(num_input, 100)  # Input dimension is 7, output dimension is 100\n",
        "        # Define the first layer norm\n",
        "        self.layer_norm1 = nn.LayerNorm(100)\n",
        "        # Define the second fully connected layer\n",
        "        self.fc2 = nn.Linear(100, 100)  # Input dimension is 100, output dimension is 100\n",
        "        # Define the third fully connected layer\n",
        "        self.fc3 = nn.Linear(100, 100)  # Input dimension is 100, output dimension is 100\n",
        "        # Define the first layer norm\n",
        "        self.layer_norm2 = nn.LayerNorm(100)\n",
        "        # Define the output layer\n",
        "        self.fc4 = nn.Linear(100, num_output)  # Input dimension is 100, output dimension is 10\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the first layer with a ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Apply the first norm layer\n",
        "        x = self.layer_norm1(x)\n",
        "        # Apply the second layer with a ReLU activation\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Apply the third layer with a ReLU activation\n",
        "        x = F.relu(self.fc3(x))\n",
        "        # Apply the second norm layer\n",
        "        x = self.layer_norm2(x)\n",
        "        # Apply the output layer\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MLP(51,10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XufKmgQZQ2Gv"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define Adamax optimizer\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
        "# Define cross-entropy loss function\n",
        "criterion = DifferenceLoss()#nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0lPwf3SQ2Gv",
        "outputId": "d8fd328b-0824-4afd-b61f-0ec70534d2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: DiffE 0.1459| MSE 0.0118, Test Loss: DiffE 0.1435| MSE 0.0115\n",
            "Epoch [2/10], Train Loss: DiffE 0.1397| MSE 0.0112, Test Loss: DiffE 0.1408| MSE 0.0113\n",
            "Epoch [3/10], Train Loss: DiffE 0.1383| MSE 0.0111, Test Loss: DiffE 0.1409| MSE 0.0113\n",
            "Epoch [4/10], Train Loss: DiffE 0.1374| MSE 0.0110, Test Loss: DiffE 0.1402| MSE 0.0112\n",
            "Epoch [5/10], Train Loss: DiffE 0.1368| MSE 0.0109, Test Loss: DiffE 0.1399| MSE 0.0112\n",
            "Epoch [6/10], Train Loss: DiffE 0.1363| MSE 0.0109, Test Loss: DiffE 0.1395| MSE 0.0112\n",
            "Epoch [7/10], Train Loss: DiffE 0.1360| MSE 0.0109, Test Loss: DiffE 0.1414| MSE 0.0113\n",
            "Epoch [8/10], Train Loss: DiffE 0.1356| MSE 0.0108, Test Loss: DiffE 0.1399| MSE 0.0112\n",
            "Epoch [9/10], Train Loss: DiffE 0.1354| MSE 0.0108, Test Loss: DiffE 0.1393| MSE 0.0111\n",
            "Epoch [10/10], Train Loss: DiffE 0.1351| MSE 0.0108, Test Loss: DiffE 0.1386| MSE 0.0111\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_eval = []\n",
        "test_eval = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_eval = 0.0\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_eval += MSE(outputs.cpu().detach().numpy(), labels.cpu().detach().numpy())*inputs.size(0)\n",
        "        epoch_train_loss += loss.item()*inputs.size(0)\n",
        "    epoch_train_eval /= len(train_dataloader.dataset)\n",
        "    epoch_train_loss /= len(train_dataloader.dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_eval.append(epoch_train_eval)\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0.0\n",
        "    epoch_test_eval = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_test_eval += MSE(outputs.cpu().detach().numpy(), labels.cpu().detach().numpy())*inputs.size(0)  # Accumulate the loss for this batch\n",
        "            epoch_test_loss += loss.item()*inputs.size(0)  # Accumulate the loss for this batch\n",
        "    # Calculate average test loss for the epoch\n",
        "    epoch_test_loss /= len(test_dataloader.dataset)\n",
        "    epoch_test_eval /= len(test_dataloader.dataset)\n",
        "    test_losses.append(epoch_test_loss)\n",
        "    test_eval.append(epoch_test_eval)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: DiffE {epoch_train_loss:.4f}| MSE {epoch_train_eval:.4f}, Test Loss: DiffE {epoch_test_loss:.4f}| MSE {epoch_test_eval:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'ANN_experiment4_ver1'\n",
        "metadata = {'train_loss':train_losses,'test_loss':test_losses,'train eval':train_eval,'test eval':test_eval}\n",
        "with open(f'metadata_{name}.pickle','wb') as m:\n",
        "  pickle.dump(metadata,m,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "torch.save(model.state_dict(), f'model_{name}.pth')"
      ],
      "metadata": {
        "id": "A435SrhSD0XE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}