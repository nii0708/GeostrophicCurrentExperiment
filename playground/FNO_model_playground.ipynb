{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook documents experiments using the FNO model for geostrophic current prediction. The model is based on Li et al. (2020) but incorporates modifications to the Fourier layer using the FNO-MLP approach from Qin et al. (2024).\n",
        "\n",
        " Li, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., & Anandkumar, A. (2020). Fourier neural operator for parametric partial differential equations. arXiv preprint arXiv:2010.08895.\n",
        "\n",
        " Qin, S., Lyu, F., Peng, W., Geng, D., Wang, J., Gao, N., ... & Wang, L. L. (2024). Toward a Better Understanding of Fourier Neural Operators: Analysis and Improvement from a Spectral Perspective. arXiv preprint arXiv:2404.07200."
      ],
      "metadata": {
        "id": "Mce-8fed6l-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified FNO-MLP layer"
      ],
      "metadata": {
        "id": "rQo_-nHLCBa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "pLSaFA0AB5k4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "oBRKPFkS9Pvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQCePAk4oK46"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from datetime import date\n",
        "import torch.nn.functional as F\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ4TITDCoK5B",
        "outputId": "a560baa9-94e3-4c2b-bc2b-ef0a1055b1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/MyDrive/paper/raw_data.pickle','rb') as r:\n",
        "    raw_data = pickle.load(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing function"
      ],
      "metadata": {
        "id": "lIae8NkcC9si"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obNhDl5ZoK49"
      },
      "outputs": [],
      "source": [
        "def parse(date_string):\n",
        "    return [int(i) for i in date_string.split('-')]\n",
        "\n",
        "def get_split_index(start_index,end_index,start_date,end_date):\n",
        "    '''\n",
        "    Calculate the start and end indices for a given date range.\n",
        "\n",
        "    Args:\n",
        "        start_index (str): The start date index in the format 'YYYY-MM-DD'.\n",
        "        end_index (str): The end date index in the format 'YYYY-MM-DD'.\n",
        "        start_date (str): The start date of the date range in the format 'YYYY-MM-DD'.\n",
        "        end_date (str): The end date of the date range in the format 'YYYY-MM-DD'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two integers:\n",
        "            - index_start (int): The number of days from the start_date to start_index.\n",
        "            - index_end (int): The number of days from the start_date to end_index, plus one.\n",
        "    '''\n",
        "    ys,ms,ds = parse(start_index)\n",
        "    ye,me,de = parse(end_index)\n",
        "    ysd,msd,dsd = parse(start_date)\n",
        "    yed,med,ded = parse(end_date)\n",
        "    start_time = date(ys,ms,ds)\n",
        "    end_time   = date(ye,me,de)\n",
        "    start_time_date = date(ysd,msd,dsd)\n",
        "    end_time_date   = date(yed,med,ded)\n",
        "    index_start = (start_time - start_time_date).days\n",
        "    index_end   = (end_time - start_time_date).days+1\n",
        "    if index_start < 0 or (end_time - end_time_date).days > 0 or end_time==start_time:\n",
        "        raise ValueError(f'index date invalid with condition {index_start} < 0 or {(end_time - end_time_date).days} > 0 or {end_time} == {start_time}')\n",
        "    return index_start,index_end"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Because the data have island which encoded as NaN\n",
        "# The need to fill the nan data is necessary\n",
        "# we use interpolation 2D\n",
        "\n",
        "def interpolate_nan_cubic(arr,method):\n",
        "    # Coordinates of non-NaN values\n",
        "    x, y = np.meshgrid(np.arange(arr.shape[1]), np.arange(arr.shape[0]))\n",
        "    x = x[~np.isnan(arr)]\n",
        "    y = y[~np.isnan(arr)]\n",
        "    points = (x, y)\n",
        "\n",
        "    # Values of non-NaN elements\n",
        "    values = arr[~np.isnan(arr)]\n",
        "\n",
        "    # Grid to interpolate onto\n",
        "    xi, yi = np.meshgrid(np.arange(arr.shape[1]), np.arange(arr.shape[0]))\n",
        "\n",
        "    # Perform cubic interpolation\n",
        "    arr_interp = griddata(points, values, (xi, yi), method=method)\n",
        "\n",
        "    return arr_interp"
      ],
      "metadata": {
        "id": "UDLSSf4OH5Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaKVBnuMoK5B"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load data to\n",
        "\n",
        "class FNOData():\n",
        "    def __init__(self,\n",
        "                 start_index_date,\n",
        "                 split_index_date,\n",
        "                 end_index_date,\n",
        "                 number_in = 1,\n",
        "                 number_out = 5,\n",
        "                 start_date=\"2013-01-01\",\n",
        "                 end_date=\"2021-12-31\"\n",
        "                 ):\n",
        "        self.start, self.split = get_split_index(start_index_date, split_index_date,start_date,end_date)\n",
        "        _         , self.end   = get_split_index(split_index_date, end_index_date,  start_date,end_date)\n",
        "        self.number_in = number_in\n",
        "        self.number_out = number_out\n",
        "        self.mask = None\n",
        "\n",
        "    def process_nan(self,X_u,X_v,X_adt,Y_u,Y_v,train):\n",
        "        if self.mask is None and train:\n",
        "          self.mask = {}\n",
        "          self.mask['u']   = X_u.nanmean()#axis=[1,2])\n",
        "          self.mask['v']   = X_v.nanmean()#axis=[1,2])\n",
        "          self.mask['adt'] = X_adt.nanmean()#axis=[1,2])\n",
        "        elif train is None:\n",
        "            AssertionError\n",
        "        X_u = torch.nan_to_num(X_u, self.mask['u'])\n",
        "        X_v = torch.nan_to_num(X_v, self.mask['v'])\n",
        "        X_adt = torch.nan_to_num(X_adt, self.mask['adt'])\n",
        "        Y_u = torch.nan_to_num(Y_u, self.mask['u'])\n",
        "        Y_v = torch.nan_to_num(Y_v, self.mask['v'])\n",
        "\n",
        "        return X_u,X_v,X_adt,Y_u,Y_v\n",
        "\n",
        "    def transform(self,data,train):\n",
        "        if train:\n",
        "            upper_bound = self.start\n",
        "            lower_bound = self.split\n",
        "        else:\n",
        "            upper_bound = self.split\n",
        "            lower_bound = self.end\n",
        "        for index in range(len(data['center'])):\n",
        "            # mean_adt = np.nanmean(data['center'][index])\n",
        "            # mean_u = np.nanmean(data['u_geos'][index])\n",
        "            # mean_v = np.nanmean(data['v_geos'][index])\n",
        "            #data['center'][index] = interpolate_nan_cubic(interpolate_nan_cubic(raw_data['center'][index],'linear'),'nearest')#np.nan_to_num(data['center'][index], nan=mean_adt)\n",
        "            data['u_geos'][index] = interpolate_nan_cubic(interpolate_nan_cubic(raw_data['u_geos'][index],'linear'),'nearest')#np.nan_to_num(data['u_geos'][index], nan=mean_adt)\n",
        "            data['v_geos'][index] = interpolate_nan_cubic(interpolate_nan_cubic(raw_data['v_geos'][index],'linear'),'nearest')#np.nan_to_num(data['v_geos'][index], nan=mean_adt)\n",
        "        X_u = []\n",
        "        X_v = []\n",
        "        X_adt = []\n",
        "        for input_n in range(self.number_in-1,-1,-1):\n",
        "          X_u.append(torch.tensor(np.array(data['u_geos'][max(0,upper_bound-self.number_in+1):min(lower_bound+self.number_out,3287)])).roll(input_n,dims=0)[self.number_in-1:-self.number_out,:,:])\n",
        "          X_v.append(torch.tensor(np.array(data['v_geos'][max(0,upper_bound-self.number_in+1):min(lower_bound+self.number_out,3287)])).roll(input_n,dims=0)[self.number_in-1:-self.number_out,:,:])\n",
        "          X_adt.append(torch.tensor(np.array(data['center'][max(0,upper_bound-self.number_in+1):min(lower_bound+self.number_out,3287)])).roll(input_n,dims=0)[self.number_in-1:-self.number_out,:,:])\n",
        "        Y_u = []\n",
        "        Y_v = []\n",
        "        for output_n in range(1,self.number_out+1):\n",
        "            Y_u.append(torch.tensor(np.array(data['u_geos'][max(0,upper_bound-self.number_in+1):min(lower_bound+self.number_out,3287)])).roll(-output_n,dims=0)[self.number_in-1:-self.number_out,:,:])\n",
        "            Y_v.append(torch.tensor(np.array(data['v_geos'][max(0,upper_bound-self.number_in+1):min(lower_bound+self.number_out,3287)])).roll(-output_n,dims=0)[self.number_in-1:-self.number_out,:,:])\n",
        "        X_u = torch.stack(X_u,dim=-1)\n",
        "        X_v = torch.stack(X_v,dim=-1)\n",
        "        X_adt = torch.stack(X_adt,dim=-1)\n",
        "\n",
        "        Y_u = torch.stack(Y_u,dim=-1)\n",
        "        Y_v = torch.stack(Y_v,dim=-1)\n",
        "        return X_u,X_v,X_adt,Y_u,Y_v\n",
        "\n",
        "    def get_data(self,data):\n",
        "        train_X_u,train_X_v,train_X_adt,train_Y_u,train_Y_v = self.transform(data,train=True)\n",
        "        test_X_u ,test_X_v ,test_X_adt ,test_Y_u ,test_Y_v  = self.transform(data,train=False)\n",
        "        # train_X_u,train_X_v,train_X_adt,train_Y_u,train_Y_v = self.process_nan(train_X_u,train_X_v,train_X_adt,train_Y_u,train_Y_v, train = True)\n",
        "        # test_X_u ,test_X_v ,test_X_adt ,test_Y_u ,test_Y_v  = self.process_nan(test_X_u ,test_X_v ,test_X_adt ,test_Y_u ,test_Y_v, train = False)\n",
        "        train = [train_X_u.float(),train_X_v.float(),train_X_adt.float(),train_Y_u.float(),train_Y_v.float()]\n",
        "        test =  [test_X_u.float() ,test_X_v.float() ,test_X_adt.float() ,test_Y_u.float() ,test_Y_v.float() ]\n",
        "        print(len(train))\n",
        "        return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be5kFsFzoK5D"
      },
      "outputs": [],
      "source": [
        "dataset=FNOData(\"2013-01-01\",\"2018-12-31\",\"2021-12-31\",number_in = 7,number_out = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWaiCvWWoK5D"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = dataset.get_data(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# with open('/content/drive/MyDrive/paper/FNO_train.picle', 'wb') as f:\n",
        "#     pickle.dump(train_data, f)\n",
        "\n",
        "# with open('/content/drive/MyDrive/paper/FNO_test.picle', 'wb') as f:\n",
        "#     pickle.dump(test_data, f)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/paper/FNO_train.picle', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/paper/FNO_test.picle', 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "6PPTX7AuqeKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTo5BPuyoK5J"
      },
      "outputs": [],
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width, in_time, out_time,do_percentage):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "        self.do_percentage = do_percentage\n",
        "        self.in_time = in_time\n",
        "        self.out_time = out_time\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(3+2, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.fc0_U = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_U = nn.Linear(self.width, 128)\n",
        "        self.fc2_U = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.fc0_V = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_V = nn.Linear(self.width, 128)\n",
        "        self.fc2_V = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.fc0_adt = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_adt = nn.Linear(self.width, 128)\n",
        "        self.fc2_adt = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.conv_join_U = SpectralConv2d_fast(self.width*2, self.width, self.modes1, self.modes2)\n",
        "        self.w_join_U = nn.Conv2d(self.width*2, self.width,1)\n",
        "\n",
        "        self.conv_join_V = SpectralConv2d_fast(self.width*2, self.width, self.modes1, self.modes2)\n",
        "        self.w_join_V = nn.Conv2d(self.width*2, self.width,1)\n",
        "\n",
        "        self.batch_norm = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.drop_out = nn.Dropout(p=self.do_percentage)\n",
        "\n",
        "    def forward(self, X_u, X_v):#, X_adt):\n",
        "        #init grid\n",
        "        grid = self.get_grid(X_u.shape, X_u.device)\n",
        "\n",
        "        #PRE - U\n",
        "\n",
        "        #attention\n",
        "        X_u = torch.cat((X_u, grid), dim=-1)\n",
        "        X_u = self.fc0_U(X_u)\n",
        "        X_u = X_u.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_u1 = self.conv0_U(X_u)\n",
        "        # X_u2 = self.w0_U(X_u)\n",
        "        # X_u = X_u1 + X_u2\n",
        "        # X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        X_u1 = self.conv1_U(X_u)\n",
        "        X_u2 = self.w1_U(X_u)\n",
        "        X_u = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "        X_u = self.drop_out(X_u)\n",
        "        #PRE - V\n",
        "\n",
        "        #attention\n",
        "        X_v = torch.cat((X_v, grid), dim=-1)\n",
        "        X_v = self.fc0_V(X_v)\n",
        "        X_v = X_v.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_v1 = self.conv0_V(X_v)\n",
        "        # X_v2 = self.w0_V(X_v)\n",
        "        # X_v = X_v1 + X_v2\n",
        "        # X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        X_v1 = self.conv1_V(X_v)\n",
        "        X_v2 = self.w1_V(X_v)\n",
        "        X_v = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "        X_v = self.drop_out(X_v)\n",
        "        #PRE - ADT\n",
        "\n",
        "        #attention\n",
        "        # X_adt = torch.cat((X_adt, grid), dim=-1)\n",
        "        # X_adt = self.fc0_adt(X_adt)\n",
        "        # X_adt = X_adt.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_adt1 = self.conv0_adt(X_adt)\n",
        "        # X_adt2 = self.w0_adt(X_adt)\n",
        "        # X_adt = X_adt1 + X_adt2\n",
        "        # X_adt = self.batch_norm(F.gelu(X_adt))\n",
        "\n",
        "        # X_adt1 = self.conv1_adt(X_adt)\n",
        "        # X_adt2 = self.w1_adt(X_adt)\n",
        "        # X_adt = X_adt1 + X_adt2\n",
        "        # X_adt = self.batch_norm(F.gelu(X_adt))\n",
        "\n",
        "        #print(X_adt.shape)\n",
        "\n",
        "        #Join channel\n",
        "        X = torch.cat([X_u,X_v],dim=1)#,X_adt],dim=1)\n",
        "\n",
        "        #POST - U\n",
        "        X_u1 = self.conv_join_U(X)\n",
        "        X_u2 = self.w_join_U(X)\n",
        "        X_u  = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "        X_u = self.drop_out(X_u)\n",
        "\n",
        "        X_u1 = self.conv2_U(X_u)\n",
        "        X_u2 = self.w2_U(X_u)\n",
        "        X_u = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "        X_u = self.drop_out(X_u)\n",
        "\n",
        "        # X_u1 = self.conv3_U(X_u)\n",
        "        # X_u2 = self.w3_U(X_u)\n",
        "        # X_u = X_u1 + X_u2\n",
        "        # X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        X_u = X_u.permute(0, 2, 3, 1)\n",
        "        X_u = self.fc1_U(X_u)\n",
        "        X_u = F.gelu(X_u)\n",
        "        X_u = self.fc2_U(X_u)\n",
        "\n",
        "        #POST - V\n",
        "        X_v1 = self.conv_join_V(X)\n",
        "        X_v2 = self.w_join_V(X)\n",
        "        X_v  = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "        X_v = self.drop_out(X_v)\n",
        "\n",
        "        X_v1 = self.conv2_V(X_v)\n",
        "        X_v2 = self.w2_V(X_v)\n",
        "        X_v = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "        X_v = self.drop_out(X_v)\n",
        "\n",
        "        # X_v1 = self.conv3_V(X_v)\n",
        "        # X_v2 = self.w3_V(X_v)\n",
        "        # X_v = X_v1 + X_v2\n",
        "        # X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        X_v = X_v.permute(0, 2, 3, 1)\n",
        "        X_v = self.fc1_V(X_v)\n",
        "        X_v = F.gelu(X_v)\n",
        "        X_v = self.fc2_V(X_v)\n",
        "\n",
        "        #- x1 = self.conv2(x)\n",
        "        #- x2 = self.w2(x)\n",
        "        #- x = x1 + x2\n",
        "        #- x = F.gelu(x + self.bn2(x))\n",
        "\n",
        "        #- x1 = self.conv3(x)\n",
        "        #- x2 = self.w3(x)\n",
        "        #- x = x1 + x2\n",
        "        # x = F.gelu(x + self.bn3(x))\n",
        "\n",
        "        # x1 = self.conv4(x)\n",
        "        # x2 = self.w4(x)\n",
        "        # x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        # x = x.permute(0, 2, 3, 1)\n",
        "        # x = self.fc1(x)\n",
        "        # x = F.gelu(x)\n",
        "        # x = self.fc2(x)\n",
        "        return X_u,X_v\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgw4z3maI8rL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class FNODataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Example assumes CSV contains image paths and text data\n",
        "        X_u   = self.data[0][idx,:,:,:]\n",
        "        X_v   = self.data[1][idx,:,:,:]\n",
        "        X_adt = self.data[2][idx,:,:,:]\n",
        "        Y_u   = self.data[3][idx,:,:,:]\n",
        "        Y_v   = self.data[4][idx,:,:,:]\n",
        "\n",
        "        return X_u,X_v,X_adt,Y_u,Y_v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjAzBolX83OH"
      },
      "outputs": [],
      "source": [
        "from numpy import linalg as LA\n",
        "def MSE(outputs, targets):\n",
        "  \"\"\"\n",
        "  Calculate the combined L1 and L2 loss.\n",
        "\n",
        "  Args:\n",
        "    outputs (torch.Tensor): The predictions of the model.\n",
        "    targets (torch.Tensor): The actual values.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The calculated loss.\n",
        "  \"\"\"\n",
        "  num_examples = outputs.shape[0]\n",
        "  true = targets.reshape(num_examples,-1)\n",
        "  pred = outputs.reshape(num_examples,-1)\n",
        "  reconstruction_error = np.mean(np.power((pred-true),2))\n",
        "  return reconstruction_error\n",
        "\n",
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
        "        super(LpLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def abs(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        #Assume uniform mesh\n",
        "        h = 1.0 / (x.size()[1] - 1.0)\n",
        "\n",
        "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(all_norms)\n",
        "            else:\n",
        "                return torch.sum(all_norms)\n",
        "\n",
        "        return all_norms\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(diff_norms/y_norms)\n",
        "            else:\n",
        "                return torch.sum(diff_norms/y_norms)\n",
        "\n",
        "        return diff_norms/y_norms\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)\n",
        "\n",
        "class DifferenceLoss(nn.Module):\n",
        "    def __init__(self, epsilon=0.001):\n",
        "        \"\"\"\n",
        "        Initialize the loss function.\n",
        "\n",
        "        Args:\n",
        "            alpha (float): The weight given to L1 loss. (1 - alpha) will be the weight for L2 loss.\n",
        "        \"\"\"\n",
        "        super(DifferenceLoss, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        \"\"\"\n",
        "        Calculate the combined L1 and L2 loss.\n",
        "\n",
        "        Args:\n",
        "            outputs (torch.Tensor): The predictions of the model.\n",
        "            targets (torch.Tensor): The actual values.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The calculated loss.\n",
        "        \"\"\"\n",
        "        num_examples = outputs.size()[0]\n",
        "        true = targets.reshape(num_examples,-1)\n",
        "        pred = outputs.reshape(num_examples,-1)\n",
        "        reconstruction_error= torch.sum(torch.pow((pred-true),2,),dim=1)\n",
        "\n",
        "        true_diff = torch.diff(targets.reshape(num_examples, -1,5))\n",
        "        pred_diff = torch.diff(outputs.reshape(num_examples, -1,5))\n",
        "        difference_error    = torch.sum(torch.pow((pred_diff-true_diff),2),dim=[1,2])\n",
        "\n",
        "        combined_loss = torch.mean(difference_error+reconstruction_error)\n",
        "        return combined_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6qO_LYOJLEd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 64#64#32\n",
        "train_dataloader = DataLoader(FNODataset(train_data), batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(FNODataset(test_data), batch_size=batch_size)\n",
        "\n",
        "template_data = torch.isnan(torch.cat([torch.tensor(np.array(raw_data['center'])),\n",
        "           torch.tensor(np.array(raw_data['u_geos'])),\n",
        "           torch.tensor(np.array(raw_data['v_geos']))])).any(dim=0)\n",
        "\n",
        "expanded_mask = template_data.unsqueeze(0).unsqueeze(0).permute(0,2,3,1)\n",
        "expanded_mask_transformed = expanded_mask.expand(32,91,195,5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for u,v,adt,U,V in train_dataloader:\n",
        "  break"
      ],
      "metadata": {
        "id": "tzXRO4hyMc50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U[~expanded_mask_transformed].shape[0]/(64*5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGuBwet3dHqA",
        "outputId": "54ca7521-4606-4b2f-d826-42c0057a6c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14374.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "91*195"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zubQ_Ed-dQUr",
        "outputId": "778cff58-7528-4318-f7d7-6ac1ecaab3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17745"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multimodal"
      ],
      "metadata": {
        "id": "gHRpilyQ4_KV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jspBfCRU-FP6",
        "outputId": "916362cd-f9ac-40ca-ba2b-5219ad2717b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0\n",
            "15.0\n"
          ]
        }
      ],
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width, in_time, out_time):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "        self.in_time = in_time\n",
        "        self.out_time = out_time\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(3+2, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.fc0_U = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_U = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_U = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_U = nn.Linear(self.width, 128)\n",
        "        self.fc2_U = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.fc0_V = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_V = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_V = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_V = nn.Linear(self.width, 128)\n",
        "        self.fc2_V = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.fc0_adt = nn.Linear(self.in_time+2, self.width)\n",
        "        self.conv0_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4_adt = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4_adt = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.fc1_adt = nn.Linear(self.width, 128)\n",
        "        self.fc2_adt = nn.Linear(128, self.out_time)\n",
        "\n",
        "        self.conv_join_U = SpectralConv2d_fast(self.width*2, self.width, self.modes1, self.modes2)\n",
        "        self.w_join_U = nn.Conv2d(self.width*2, self.width,1)\n",
        "\n",
        "        self.conv_join_V = SpectralConv2d_fast(self.width*2, self.width, self.modes1, self.modes2)\n",
        "        self.w_join_V = nn.Conv2d(self.width*2, self.width,1)\n",
        "\n",
        "        self.batch_norm = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "    def forward(self, X_u, X_v):#, X_adt):\n",
        "        #init grid\n",
        "        grid = self.get_grid(X_u.shape, X_u.device)\n",
        "\n",
        "        #PRE - U\n",
        "\n",
        "        #attention\n",
        "        X_u = torch.cat((X_u, grid), dim=-1)\n",
        "        X_u = self.fc0_U(X_u)\n",
        "        X_u = X_u.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_u1 = self.conv0_U(X_u)\n",
        "        # X_u2 = self.w0_U(X_u)\n",
        "        # X_u = X_u1 + X_u2\n",
        "        # X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        X_u1 = self.conv1_U(X_u)\n",
        "        X_u2 = self.w1_U(X_u)\n",
        "        X_u = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        #PRE - V\n",
        "\n",
        "        #attention\n",
        "        X_v = torch.cat((X_v, grid), dim=-1)\n",
        "        X_v = self.fc0_V(X_v)\n",
        "        X_v = X_v.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_v1 = self.conv0_V(X_v)\n",
        "        # X_v2 = self.w0_V(X_v)\n",
        "        # X_v = X_v1 + X_v2\n",
        "        # X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        X_v1 = self.conv1_V(X_v)\n",
        "        X_v2 = self.w1_V(X_v)\n",
        "        X_v = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        #PRE - ADT\n",
        "\n",
        "        #attention\n",
        "        # X_adt = torch.cat((X_adt, grid), dim=-1)\n",
        "        # X_adt = self.fc0_adt(X_adt)\n",
        "        # X_adt = X_adt.permute(0, 3, 1, 2)\n",
        "\n",
        "        # X_adt1 = self.conv0_adt(X_adt)\n",
        "        # X_adt2 = self.w0_adt(X_adt)\n",
        "        # X_adt = X_adt1 + X_adt2\n",
        "        # X_adt = self.batch_norm(F.gelu(X_adt))\n",
        "\n",
        "        # X_adt1 = self.conv1_adt(X_adt)\n",
        "        # X_adt2 = self.w1_adt(X_adt)\n",
        "        # X_adt = X_adt1 + X_adt2\n",
        "        # X_adt = self.batch_norm(F.gelu(X_adt))\n",
        "\n",
        "        #print(X_adt.shape)\n",
        "\n",
        "        #Join channel\n",
        "        X = torch.cat([X_u,X_v],dim=1)#,X_adt],dim=1)\n",
        "\n",
        "        #POST - U\n",
        "        X_u1 = self.conv_join_U(X)\n",
        "        X_u2 = self.w_join_U(X)\n",
        "        X_u  = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        X_u1 = self.conv2_U(X_u)\n",
        "        X_u2 = self.w2_U(X_u)\n",
        "        X_u = X_u1 + X_u2\n",
        "        X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        # X_u1 = self.conv3_U(X_u)\n",
        "        # X_u2 = self.w3_U(X_u)\n",
        "        # X_u = X_u1 + X_u2\n",
        "        # X_u = self.batch_norm(F.gelu(X_u))\n",
        "\n",
        "        X_u = X_u.permute(0, 2, 3, 1)\n",
        "        X_u = self.fc1_U(X_u)\n",
        "        X_u = F.gelu(X_u)\n",
        "        X_u = self.fc2_U(X_u)\n",
        "\n",
        "        #POST - V\n",
        "        X_v1 = self.conv_join_V(X)\n",
        "        X_v2 = self.w_join_V(X)\n",
        "        X_v  = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        X_v1 = self.conv2_V(X_v)\n",
        "        X_v2 = self.w2_V(X_v)\n",
        "        X_v = X_v1 + X_v2\n",
        "        X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        # X_v1 = self.conv3_V(X_v)\n",
        "        # X_v2 = self.w3_V(X_v)\n",
        "        # X_v = X_v1 + X_v2\n",
        "        # X_v = self.batch_norm(F.gelu(X_v))\n",
        "\n",
        "        X_v = X_v.permute(0, 2, 3, 1)\n",
        "        X_v = self.fc1_V(X_v)\n",
        "        X_v = F.gelu(X_v)\n",
        "        X_v = self.fc2_V(X_v)\n",
        "\n",
        "        #- x1 = self.conv2(x)\n",
        "        #- x2 = self.w2(x)\n",
        "        #- x = x1 + x2\n",
        "        #- x = F.gelu(x + self.bn2(x))\n",
        "\n",
        "        #- x1 = self.conv3(x)\n",
        "        #- x2 = self.w3(x)\n",
        "        #- x = x1 + x2\n",
        "        # x = F.gelu(x + self.bn3(x))\n",
        "\n",
        "        # x1 = self.conv4(x)\n",
        "        # x2 = self.w4(x)\n",
        "        # x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        # x = x.permute(0, 2, 3, 1)\n",
        "        # x = self.fc1(x)\n",
        "        # x = F.gelu(x)\n",
        "        # x = self.fc2(x)\n",
        "        return X_u,X_v\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FNO2d(7*4, 15*4, width=30, in_time=7, out_time=1).to(device)#24, 52\n",
        "\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=0.003, weight_decay=1e-1)\n",
        "myloss = LpLoss(size_average=True)#torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "WSoeAyVi49Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "pq4Tltx2VmRc",
        "outputId": "0a992424-8aef-4705-deb7-4957163a7303"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 3",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-37a0b7df4289>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;31m# u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-99f00411b3f0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Example assumes CSV contains image paths and text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX_u\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mX_v\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX_adt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
          ]
        }
      ],
      "source": [
        "for z in train_dataloader:\n",
        "  # u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "  # break\n",
        "  print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4D9cUQzh1mC",
        "outputId": "121fbbef-7e42-4cd8-f4eb-a23393365d4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1363,  0.1452,  0.1658,  ..., -0.0090, -0.0090, -0.0090],\n",
              "        [ 0.0943,  0.1304,  0.1600,  ..., -0.0090, -0.0090, -0.0090],\n",
              "        [ 0.0790,  0.0825,  0.1358,  ..., -0.0090, -0.0090, -0.0090],\n",
              "        ...,\n",
              "        [ 0.2434,  0.1770,  0.0860,  ...,  0.0947,  0.1047,  0.0945],\n",
              "        [ 0.2514,  0.1991,  0.0703,  ...,  0.0815,  0.0886,  0.0759],\n",
              "        [ 0.2936,  0.1830,  0.0033,  ...,  0.0415,  0.0691,  0.0664]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "true[...,1::5][0,:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxZrJwoz466N",
        "outputId": "e0f24e85-7864-4679-d717-93fc91ff5c5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 91, 195, 10])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t=0\n",
        "true[..., t:t + 1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJfRoNmu6bxr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "1fd9eeba-baa3-4b3c-b356-0de964bfc536"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FNO2d.forward() takes 3 positional arguments but 4 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-03373fe966b5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mexpanded_mask_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpanded_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m195\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m#construct data for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FNO2d.forward() takes 3 positional arguments but 4 were given"
          ]
        }
      ],
      "source": [
        "num_epochs = 4\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_eval = []\n",
        "test_eval = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_eval = 0.0\n",
        "\n",
        "    for u,v,adt,U,V in train_dataloader:\n",
        "        u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "        batch = u.shape[0]\n",
        "        expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(u,v,adt)\n",
        "        #construct data for loss\n",
        "        outputs = torch.cat([outputs[0],outputs[1]],dim=-1)\n",
        "        true = torch.cat([U,V],dim=-1)\n",
        "        #count loss\n",
        "        loss = myloss(outputs, true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_eval += MSE(outputs[~expanded_mask_transformed].cpu().detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)\n",
        "        epoch_train_loss += loss.item()*u.size(0)\n",
        "    epoch_train_eval /= len(train_dataloader.dataset)\n",
        "    epoch_train_loss /= len(train_dataloader.dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_eval.append(epoch_train_eval)\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0.0\n",
        "    epoch_test_eval = 0.0\n",
        "    with torch.no_grad():\n",
        "        for u,v,adt,U,V in test_dataloader:\n",
        "            batch = u.shape[0]\n",
        "            expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "            u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "            outputs = model(u,v,adt)\n",
        "            outputs = torch.cat([outputs[0],outputs[1]],dim=-1)\n",
        "            true = torch.cat([U,V],dim=-1)\n",
        "            #count loss\n",
        "            loss = myloss(outputs, true)\n",
        "            epoch_test_eval += MSE(outputs.cpu()[~expanded_mask_transformed].detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)  # Accumulate the loss for this batch\n",
        "            epoch_test_loss += loss.item()*u.size(0)  # Accumulate the loss for this batch\n",
        "    # Calculate average test loss for the epoch\n",
        "    epoch_test_loss /= len(test_dataloader.dataset)\n",
        "    epoch_test_eval /= len(test_dataloader.dataset)\n",
        "    test_losses.append(epoch_test_loss)\n",
        "    test_eval.append(epoch_test_eval)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: DiffE {epoch_train_loss:.4f}| MSE {epoch_train_eval:.4f}, Test Loss: DiffE {epoch_test_loss:.4f}| MSE {epoch_test_eval:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 INPUT MODEL RNN"
      ],
      "metadata": {
        "id": "3IYlDrz44NcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 1"
      ],
      "metadata": {
        "id": "zCyMoRtTldwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)#,norm =\"ortho\")\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))#, norm=\"ortho\")\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width,do_percentage):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "        self.do_percentage = do_percentage\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc_e0 = nn.Linear(9, self.width)\n",
        "        # self.fc_e1 = nn.Linear(self.width*3, self.width*3)\n",
        "        # self.fc_e2 = nn.Linear(self.width*3, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.drop_out = nn.Dropout(p=self.do_percentage)\n",
        "\n",
        "    def forward(self, x, train= True):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc_e0(x)\n",
        "        # x = F.gelu(self.fc_e1(x))\n",
        "        #x = F.gelu(self.fc_e2(x))\n",
        "        #x = F.gelu(x)\n",
        "        #x = self.fc1(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x_1 = F.gelu(x + self.bn0(x))\n",
        "        # if train:\n",
        "        #   x_1 = self.drop_out(x_1)\n",
        "\n",
        "        x1 = self.conv1(x_1)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x_2 = F.gelu(x + self.bn1(x))\n",
        "        # if train:\n",
        "        #   x   = self.drop_out(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn2(x))\n",
        "        # if train:\n",
        "        #   x   = self.drop_out(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn3(x))\n",
        "        x = x + x_2\n",
        "        # if train:\n",
        "        #   x   = self.drop_out(x)\n",
        "\n",
        "        x1 = self.conv4(x)\n",
        "        x2 = self.w4(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn4(x))\n",
        "        x = x + x_1\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ],
      "metadata": {
        "id": "czobVv04IVJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEIrA4igC3Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model U-DIFFLOSS"
      ],
      "metadata": {
        "id": "RgDdIdgjlgyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(9, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.m0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.m01 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m11 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m21 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m31 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        #x = F.gelu(x)\n",
        "        #x = self.fc1(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
        "\n",
        "        # x1 = self.conv0(x)\n",
        "        # x2 = self.w0(x)\n",
        "        # x = self.m01(self.gelu(self.m0(x1))) + x2\n",
        "        # x = F.gelu(x + self.bn0(x))\n",
        "\n",
        "        # x1 = self.conv1(x)\n",
        "        # x2 = self.w1(x)\n",
        "        # x = self.m11(self.gelu(self.m1(x1))) + x2\n",
        "        # x = F.gelu(x + self.bn1(x))\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = self.m21(F.gelu(self.m2(x1))) + x2\n",
        "        x = F.gelu(x + self.bn2(x))\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = self.m31(F.gelu(self.m3(x1))) + x2\n",
        "        #x = F.gelu(x + self.bn3(x))\n",
        "\n",
        "        #x1 = self.conv4(x)\n",
        "        #x2 = self.w4(x)\n",
        "        #x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ],
      "metadata": {
        "id": "Z1xxtNR_mVkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FNO2d(35,66, width=50).cuda()#, do_percentage=0.2).cuda()#7*5, 15*5model = FNO2d(35,66, width=30).cuda()#\n",
        "#model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 0.0005\n",
        "scheduler_step = 10\n",
        "scheduler_gamma = 0.9\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_eval = []\n",
        "test_eval = []\n",
        "\n",
        "myloss = nn.MSELoss()#LpLoss(size_average=True)\n",
        "saver = BestModelSaver(metric_name='loss', min_best=True, filepath='best_model.pth')\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for ep in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_eval = 0.0\n",
        "    for u,v,adt,U,V in train_dataloader:\n",
        "        batch = u.shape[0]\n",
        "        loss = 0\n",
        "        u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "        batch = v.shape[0]\n",
        "        expanded_mask_transformed = expanded_mask.expand(batch,91,195,5)\n",
        "        expanded_mask_transformed1= expanded_mask.expand(batch,91,195,1)\n",
        "\n",
        "\n",
        "        for t in range(0, 5, 1):\n",
        "\n",
        "            outputs = model(u)#,adt)\n",
        "            true = U\n",
        "            y = true[...,t:t+1]\n",
        "            #loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "            #loss += myloss(outputs[~expanded_mask_transformed1].reshape(batch, -1), y[~expanded_mask_transformed1].reshape(batch, -1))\n",
        "            if t == 0:\n",
        "                pred = outputs\n",
        "            else:\n",
        "                pred = torch.cat((pred, outputs), -1)\n",
        "            # print(u[..., 1:].shape)\n",
        "            # print(outputs[...,0:1].shape)\n",
        "            u = torch.cat((u[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "            #v = torch.cat((v[..., 1:], outputs[...,1:2]), dim=-1)\n",
        "            #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "\n",
        "        #l2_full = myloss(pred.reshape(batch, -1), true.reshape(batch, -1))\n",
        "        l2_full = myloss(pred[~expanded_mask_transformed].reshape(batch, -1), true[~expanded_mask_transformed].reshape(batch, -1))\n",
        "\n",
        "        epoch_train_loss += l2_full.item()*u.size(0)\n",
        "        epoch_train_eval += MSE(pred[~expanded_mask_transformed].cpu().detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        l2_full.backward()\n",
        "        optimizer.step()\n",
        "    epoch_train_eval /= len(train_dataloader.dataset)\n",
        "    epoch_train_loss /= len(train_dataloader.dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_eval.append(epoch_train_eval)\n",
        "#------\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0.0\n",
        "    epoch_test_eval = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for u,v,adt,U,V in test_dataloader:\n",
        "            loss = 0\n",
        "            batch = v.shape[0]\n",
        "            expanded_mask_transformed = expanded_mask.expand(batch,91,195,5)\n",
        "            u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "\n",
        "            for t in range(0, 5, 1):\n",
        "                outputs = model(u)#,train=False)#,adt)\n",
        "                true = U\n",
        "\n",
        "                y = true[...,t:t+1]\n",
        "                #loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = outputs\n",
        "                else:\n",
        "                    pred = torch.cat((pred, outputs), -1)\n",
        "\n",
        "                u = torch.cat((u[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "                #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "            l2_full = myloss(pred[~expanded_mask_transformed].reshape(batch, -1), true[~expanded_mask_transformed].reshape(batch, -1))#myloss(pred, true)\n",
        "            epoch_test_eval += MSE(pred.cpu()[~expanded_mask_transformed].detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)  # Accumulate the loss for this batch\n",
        "            epoch_test_loss += l2_full.item()*u.size(0)  # Accumulate the loss for this batch\n",
        "    # Calculate average test loss for the epoch\n",
        "    epoch_test_loss /= len(test_dataloader.dataset)\n",
        "    epoch_test_eval /= len(test_dataloader.dataset)\n",
        "    test_losses.append(epoch_test_loss)\n",
        "    test_eval.append(epoch_test_eval)\n",
        "    saver.update(epoch_test_eval, model)\n",
        "    print(f'Epoch [{ep+1}/{num_epochs}], Train Loss: DiffE {epoch_train_loss:.4f}| MSE {epoch_train_eval:.4f}, Test Loss: DiffE {epoch_test_loss:.4f}| MSE {epoch_test_eval:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jILCjAaDRrQ",
        "outputId": "d85691a3-c254-4bf7-82b1-ea80c85c7195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model with loss: 0.019366199944567834 to best_model.pth\n",
            "Epoch [1/10], Train Loss: DiffE 0.0292| MSE 0.0292, Test Loss: DiffE 0.0194| MSE 0.0194\n",
            "Saved model with loss: 0.01709818549959568 to best_model.pth\n",
            "Epoch [2/10], Train Loss: DiffE 0.0177| MSE 0.0177, Test Loss: DiffE 0.0171| MSE 0.0171\n",
            "Saved model with loss: 0.01598426559470478 to best_model.pth\n",
            "Epoch [3/10], Train Loss: DiffE 0.0162| MSE 0.0162, Test Loss: DiffE 0.0160| MSE 0.0160\n",
            "Saved model with loss: 0.014759836947215903 to best_model.pth\n",
            "Epoch [4/10], Train Loss: DiffE 0.0149| MSE 0.0149, Test Loss: DiffE 0.0148| MSE 0.0148\n",
            "Saved model with loss: 0.013222258462033667 to best_model.pth\n",
            "Epoch [5/10], Train Loss: DiffE 0.0134| MSE 0.0134, Test Loss: DiffE 0.0132| MSE 0.0132\n",
            "Saved model with loss: 0.01272550516520259 to best_model.pth\n",
            "Epoch [6/10], Train Loss: DiffE 0.0123| MSE 0.0123, Test Loss: DiffE 0.0127| MSE 0.0127\n",
            "Saved model with loss: 0.012365482674141634 to best_model.pth\n",
            "Epoch [7/10], Train Loss: DiffE 0.0118| MSE 0.0118, Test Loss: DiffE 0.0124| MSE 0.0124\n",
            "Saved model with loss: 0.012218337090332557 to best_model.pth\n",
            "Epoch [8/10], Train Loss: DiffE 0.0115| MSE 0.0115, Test Loss: DiffE 0.0122| MSE 0.0122\n",
            "Saved model with loss: 0.012104586721163185 to best_model.pth\n",
            "Epoch [9/10], Train Loss: DiffE 0.0113| MSE 0.0113, Test Loss: DiffE 0.0121| MSE 0.0121\n",
            "Saved model with loss: 0.012028814431734034 to best_model.pth\n",
            "Epoch [10/10], Train Loss: DiffE 0.0110| MSE 0.0110, Test Loss: DiffE 0.0120| MSE 0.0120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# name = 'FNO_U-lossMSE'\n",
        "# metadata = {'train_loss':train_losses,'test_loss':test_losses,'train eval':train_eval,'test eval':test_eval}\n",
        "# with open(f'metadata_{name}.pickle','wb') as m:\n",
        "#   pickle.dump(metadata,m,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# torch.save(model, f'model_{name}.pth')\n",
        "\n",
        "import shutil\n",
        "name_best = './model_FNO_U-lossMSE.pth'\n",
        "# Source file path in Colab environment\n",
        "source = f'/content/{name_best}'#model_FNO_experiment1_ver2_2.pth'\n",
        "\n",
        "# Destination folder path in Google Drive\n",
        "destination = f'/content/drive/MyDrive/paper/{name_best}'#model_FNO_experiment1_ver2_2.pth'\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source, destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uUH4WC8Eja5J",
        "outputId": "26c72a85-2cf0-49d6-f245-23e4bb4abc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/paper/./model_FNO_U-lossMSE.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model V diff Loss"
      ],
      "metadata": {
        "id": "gaHMRMR0C8jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(9, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.m0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.m01 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m11 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m21 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.m31 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        #x = F.gelu(x)\n",
        "        #x = self.fc1(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
        "\n",
        "        # x1 = self.conv0(x)\n",
        "        # x2 = self.w0(x)\n",
        "        # x = self.m01(self.gelu(self.m0(x1))) + x2\n",
        "        # x = F.gelu(x + self.bn0(x))\n",
        "\n",
        "        # x1 = self.conv1(x)\n",
        "        # x2 = self.w1(x)\n",
        "        # x = self.m11(self.gelu(self.m1(x1))) + x2\n",
        "        # x = F.gelu(x + self.bn1(x))\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = self.m21(F.gelu(self.m2(x1))) + x2\n",
        "        x = F.gelu(x + self.bn2(x))\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = self.m31(F.gelu(self.m3(x1))) + x2\n",
        "        #x = F.gelu(x + self.bn3(x))\n",
        "\n",
        "        #x1 = self.conv4(x)\n",
        "        #x2 = self.w4(x)\n",
        "        #x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ],
      "metadata": {
        "id": "yLSJbLWQC-yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class BestModelSaver:\n",
        "    def __init__(self, metric_name='loss', min_best=True, filepath='best_model.pth'):\n",
        "        self.metric_name = metric_name\n",
        "        self.min_best = min_best\n",
        "        self.best_metric = float('inf') if min_best else float('-inf')\n",
        "        self.filepath = filepath\n",
        "        self.best_model = None\n",
        "\n",
        "    def update(self, current_metric, model):\n",
        "        if self.min_best and current_metric < self.best_metric:\n",
        "            self.best_metric = current_metric\n",
        "            self.best_model = model\n",
        "            self.save()\n",
        "        elif not self.min_best and current_metric > self.best_metric:\n",
        "            self.best_metric = current_metric\n",
        "            self.best_model = model\n",
        "            self.save()\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.best_model, self.filepath)\n",
        "        print(f\"Saved model with {self.metric_name}: {self.best_metric} to {self.filepath}\")\n"
      ],
      "metadata": {
        "id": "eYIKw0m33AcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FNO2d(35,66, width=50).cuda()#, do_percentage=0.2).cuda()#7*5, 15*5model = FNO2d(35,66, width=30).cuda()#\n",
        "#model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
        "\n",
        "learning_rate = 0.0005\n",
        "scheduler_step = 10\n",
        "scheduler_gamma = 0.9\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_eval = []\n",
        "test_eval = []\n",
        "\n",
        "myloss = LpLoss(size_average=True)#DifferenceLoss()\n",
        "saver = BestModelSaver(metric_name='loss', min_best=True, filepath='best_model.pth')\n",
        "\n",
        "num_epochs = 10\n",
        "for ep in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_eval = 0.0\n",
        "    for u,v,adt,U,V in train_dataloader:\n",
        "        batch = u.shape[0]\n",
        "        loss = 0\n",
        "        u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "        batch = v.shape[0]\n",
        "        expanded_mask_transformed = expanded_mask.expand(batch,91,195,5)\n",
        "        expanded_mask_transformed1= expanded_mask.expand(batch,91,195,1)\n",
        "\n",
        "\n",
        "        for t in range(0, 5, 1):\n",
        "\n",
        "            outputs = model(v)#,adt)\n",
        "            true = V\n",
        "            y = true[...,t:t+1]\n",
        "            #loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "            #loss += myloss(outputs[~expanded_mask_transformed1].reshape(batch, -1), y[~expanded_mask_transformed1].reshape(batch, -1))\n",
        "            if t == 0:\n",
        "                pred = outputs\n",
        "            else:\n",
        "                pred = torch.cat((pred, outputs), -1)\n",
        "            # print(u[..., 1:].shape)\n",
        "            # print(outputs[...,0:1].shape)\n",
        "            v = torch.cat((v[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "            #v = torch.cat((v[..., 1:], outputs[...,1:2]), dim=-1)\n",
        "            #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "\n",
        "        #l2_full = myloss(pred.reshape(batch, -1), true.reshape(batch, -1))\n",
        "        l2_full = myloss(pred, true)#myloss(pred[~expanded_mask_transformed].reshape(batch, -1), true[~expanded_mask_transformed].reshape(batch, -1))\n",
        "\n",
        "        epoch_train_loss += l2_full.item()*v.size(0)\n",
        "        epoch_train_eval += MSE(pred[~expanded_mask_transformed].cpu().detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        l2_full.backward()\n",
        "        optimizer.step()\n",
        "    epoch_train_eval /= len(train_dataloader.dataset)\n",
        "    epoch_train_loss /= len(train_dataloader.dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_eval.append(epoch_train_eval)\n",
        "#------\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0.0\n",
        "    epoch_test_eval = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for u,v,adt,U,V in test_dataloader:\n",
        "            loss = 0\n",
        "            batch = v.shape[0]\n",
        "            expanded_mask_transformed = expanded_mask.expand(batch,91,195,5)\n",
        "            u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "\n",
        "            for t in range(0, 5, 1):\n",
        "                outputs = model(v)#,train=False)#,adt)\n",
        "                true = V\n",
        "\n",
        "                y = true[...,t:t+1]\n",
        "                #loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = outputs\n",
        "                else:\n",
        "                    pred = torch.cat((pred, outputs), -1)\n",
        "\n",
        "                v = torch.cat((v[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "                #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "            l2_full = myloss(pred, true)\n",
        "            epoch_test_eval += MSE(pred.cpu()[~expanded_mask_transformed].detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*v.size(0)  # Accumulate the loss for this batch\n",
        "            epoch_test_loss += l2_full.item()*v.size(0)  # Accumulate the loss for this batch\n",
        "    # Calculate average test loss for the epoch\n",
        "    epoch_test_loss /= len(test_dataloader.dataset)\n",
        "    epoch_test_eval /= len(test_dataloader.dataset)\n",
        "    test_losses.append(epoch_test_loss)\n",
        "    test_eval.append(epoch_test_eval)\n",
        "    saver.update(epoch_test_eval, model)\n",
        "    print(f'Epoch [{ep+1}/{num_epochs}], Train Loss: DiffE {epoch_train_loss:.4f}| MSE {epoch_train_eval:.4f}, Test Loss: DiffE {epoch_test_loss:.4f}| MSE {epoch_test_eval:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29M-Z3_II6Cx",
        "outputId": "fa37c3ad-917c-4a26-cc84-e89e2e3f43e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model with loss: 0.014815277914242609 to best_model.pth\n",
            "Epoch [1/10], Train Loss: DiffE 0.6685| MSE 0.0237, Test Loss: DiffE 0.5429| MSE 0.0148\n",
            "Saved model with loss: 0.012407168611119254 to best_model.pth\n",
            "Epoch [2/10], Train Loss: DiffE 0.5096| MSE 0.0128, Test Loss: DiffE 0.4983| MSE 0.0124\n",
            "Saved model with loss: 0.010774838988260323 to best_model.pth\n",
            "Epoch [3/10], Train Loss: DiffE 0.4633| MSE 0.0106, Test Loss: DiffE 0.4618| MSE 0.0108\n",
            "Epoch [4/10], Train Loss: DiffE 0.4395| MSE 0.0096, Test Loss: DiffE 0.4673| MSE 0.0110\n",
            "Saved model with loss: 0.009798610425877746 to best_model.pth\n",
            "Epoch [5/10], Train Loss: DiffE 0.4274| MSE 0.0090, Test Loss: DiffE 0.4417| MSE 0.0098\n",
            "Saved model with loss: 0.009662146431647452 to best_model.pth\n",
            "Epoch [6/10], Train Loss: DiffE 0.4186| MSE 0.0086, Test Loss: DiffE 0.4394| MSE 0.0097\n",
            "Saved model with loss: 0.009344616565959208 to best_model.pth\n",
            "Epoch [7/10], Train Loss: DiffE 0.4132| MSE 0.0084, Test Loss: DiffE 0.4322| MSE 0.0093\n",
            "Epoch [8/10], Train Loss: DiffE 0.4085| MSE 0.0082, Test Loss: DiffE 0.4366| MSE 0.0095\n",
            "Saved model with loss: 0.009124162853597283 to best_model.pth\n",
            "Epoch [9/10], Train Loss: DiffE 0.4052| MSE 0.0081, Test Loss: DiffE 0.4279| MSE 0.0091\n",
            "Epoch [10/10], Train Loss: DiffE 0.4015| MSE 0.0079, Test Loss: DiffE 0.4335| MSE 0.0094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "567840/32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq8U8m_WGZhl",
        "outputId": "6bc4b055-985f-495d-9f43-07f3fa9ad6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17745.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giayLHAHnCpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'FNO_V-lossMSE'\n",
        "metadata = {'train_loss':train_losses,'test_loss':test_losses,'train eval':train_eval,'test eval':test_eval}\n",
        "with open(f'metadata_{name}.pickle','wb') as m:\n",
        "  pickle.dump(metadata,m,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# torch.save(model, f'model_{name}.pth')\n",
        "\n",
        "import shutil\n",
        "name_best = './model_FNO_V-lossMSE.pth'\n",
        "# Source file path in Colab environment\n",
        "source = f'/content/{name_best}'#model_FNO_experiment1_ver2_2.pth'\n",
        "\n",
        "# Destination folder path in Google Drive\n",
        "destination = f'/content/drive/MyDrive/paper/{name_best}'#model_FNO_experiment1_ver2_2.pth'\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source, destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SUj1IeilBDSm",
        "outputId": "d4ad1569-6464-40f3-d9d0-cfd737a5161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/paper/./model_FNO_V-lossMSE.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch [1/4], Train Loss: DiffE 12.6307| MSE 0.0557, Test Loss: DiffE 40.6140| MSE 0.0187\n",
        "Epoch [2/4], Train Loss: DiffE 7.9159| MSE 0.0169, Test Loss: DiffE 37.9649| MSE 0.0165\n",
        "Epoch [3/4], Train Loss: DiffE 7.4228| MSE 0.0149, Test Loss: DiffE 36.6700| MSE 0.0155\n",
        "Epoch [4/4], Train Loss: DiffE 7.2057| MSE 0.0140, Test Loss: DiffE 35.0002| MSE 0.0142"
      ],
      "metadata": {
        "id": "3kYbaDqx7pnI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0nyti9c3BCl"
      },
      "source": [
        "# AR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FNO2d(7*4, 15*4, width=30, in_time=7, out_time=1, do_percentage=0.3).to(device)#24, 52\n",
        "\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=0.003, weight_decay=1e-1)\n",
        "myloss = LpLoss(size_average=True)#torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "rfXcfQtj3jcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "vs2YHZlyYYT2",
        "outputId": "d72bb395-1b0e-4343-f618-d6972bf9f335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: DiffE 0.3516| MSE 0.0349, Test Loss: DiffE 4.4224| MSE 0.2087\n",
            "Epoch [2/10], Train Loss: DiffE 0.3047| MSE 0.0242, Test Loss: DiffE 4.4627| MSE 0.2124\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-34812f4d2633>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mepoch_train_eval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mexpanded_mask_transformed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mexpanded_mask_transformed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mepoch_train_eval\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_eval = []\n",
        "test_eval = []\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_eval = 0.0\n",
        "    for u,v,adt,U,V in train_dataloader:\n",
        "        batch = u.shape[0]\n",
        "        loss = 0\n",
        "        u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "        batch = u.shape[0]\n",
        "        expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "\n",
        "\n",
        "        for t in range(0, 5, 1):\n",
        "\n",
        "            outputs = model(u,v)#,adt)\n",
        "            outputs = torch.cat([outputs[0],outputs[1]],dim=-1)\n",
        "            true = torch.cat([U,V],dim=-1)\n",
        "            y = true[...,t::5]\n",
        "            loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "            if t == 0:\n",
        "                pred = outputs\n",
        "            else:\n",
        "                pred = torch.cat((pred, outputs), -1)\n",
        "            # print(u[..., 1:].shape)\n",
        "            # print(outputs[...,0:1].shape)\n",
        "            u = torch.cat((u[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "            v = torch.cat((v[..., 1:], outputs[...,1:2]), dim=-1)\n",
        "            #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "\n",
        "\n",
        "        pred = torch.cat([pred[...,0::2],pred[...,1::2]],dim=-1)\n",
        "        l2_full = myloss(pred.reshape(batch, -1), true.reshape(batch, -1))\n",
        "        epoch_train_loss += l2_full.item()*u.size(0)\n",
        "        epoch_train_eval += MSE(pred[~expanded_mask_transformed].cpu().detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_train_eval /= len(train_dataloader.dataset)\n",
        "    epoch_train_loss /= len(train_dataloader.dataset)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_eval.append(epoch_train_eval)\n",
        "#------\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0.0\n",
        "    epoch_test_eval = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for u,v,adt,U,V in test_dataloader:\n",
        "            loss = 0\n",
        "            batch = u.shape[0]\n",
        "            expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "            u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "\n",
        "            for t in range(0, 5, 1):\n",
        "                outputs = model(u,v)#,adt)\n",
        "                outputs = torch.cat([outputs[0],outputs[1]],dim=-1)\n",
        "                true = torch.cat([U,V],dim=-1)\n",
        "\n",
        "                y = true[...,t::5]\n",
        "                loss += myloss(outputs.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = outputs\n",
        "                else:\n",
        "                    pred = torch.cat((pred, outputs), -1)\n",
        "\n",
        "                u = torch.cat((u[..., 1:], outputs[...,0:1]), dim=-1)\n",
        "                v = torch.cat((v[..., 1:], outputs[...,1:2]), dim=-1)\n",
        "                #adt = torch.cat((adt[..., 1:], outputs), dim=-1)\n",
        "            pred = torch.cat([pred[...,0::2],pred[...,1::2]],dim=-1)\n",
        "            epoch_test_eval += MSE(pred.cpu()[~expanded_mask_transformed].detach().numpy(), true[~expanded_mask_transformed].cpu().detach().numpy())*u.size(0)  # Accumulate the loss for this batch\n",
        "            epoch_test_loss += loss.item()*u.size(0)  # Accumulate the loss for this batch\n",
        "    # Calculate average test loss for the epoch\n",
        "    epoch_test_loss /= len(test_dataloader.dataset)\n",
        "    epoch_test_eval /= len(test_dataloader.dataset)\n",
        "    test_losses.append(epoch_test_loss)\n",
        "    test_eval.append(epoch_test_eval)\n",
        "    print(f'Epoch [{ep+1}/{num_epochs}], Train Loss: DiffE {epoch_train_loss:.4f}| MSE {epoch_train_eval:.4f}, Test Loss: DiffE {epoch_test_loss:.4f}| MSE {epoch_test_eval:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD7ipSVxUZA0",
        "outputId": "07065fc6-746d-4ce3-b19f-61a997175090"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2755, -0.3023, -0.3402,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        [-0.2956, -0.3348, -0.3432,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        [-0.3088, -0.3158, -0.3127,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        ...,\n",
              "        [-0.1866, -0.2244, -0.2548,  ..., -0.0802, -0.0746, -0.0643],\n",
              "        [-0.0847, -0.1260, -0.1914,  ..., -0.0519, -0.0664, -0.0509],\n",
              "        [-0.1663, -0.1693, -0.2715,  ...,  0.0067, -0.0500, -0.1047]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "true[0,:,:,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGSWCkAsUg7O",
        "outputId": "a1e6b02b-f973-4245-bde3-60f05a0c66de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2755, -0.3023, -0.3402,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        [-0.2956, -0.3348, -0.3432,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        [-0.3088, -0.3158, -0.3127,  ...,  1.1536,  1.1536,  1.1536],\n",
              "        ...,\n",
              "        [-0.1866, -0.2244, -0.2548,  ..., -0.0802, -0.0746, -0.0643],\n",
              "        [-0.0847, -0.1260, -0.1914,  ..., -0.0519, -0.0664, -0.0509],\n",
              "        [-0.1663, -0.1693, -0.2715,  ...,  0.0067, -0.0500, -0.1047]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "U[0,:,:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTMZ-FmbZgXA",
        "outputId": "2c13eed0-d99b-4173-b200-ad85089ca0e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14374)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "91*195-template_data.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVdumMq2RfKY",
        "outputId": "23e7c2bd-5d4e-42af-a2d2-077743adef44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([143740])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs[~expanded_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dp5TIQw5TP3x",
        "outputId": "90038a87-9817-4f52-9b08-656854937d99"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'default_timer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-ab18c8c69cee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_l2_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_l2_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'default_timer' is not defined"
          ]
        }
      ],
      "source": [
        "# model = FNO2d(24, 52, width=12).cuda()\n",
        "# model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
        "epochs = 20\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2_step = 0\n",
        "    train_l2_full = 0\n",
        "    for xx, yy in train_loader:\n",
        "        loss = 0\n",
        "        xx = xx.to(device)\n",
        "        yy = yy.to(device)\n",
        "\n",
        "        for t in range(0, T, step):\n",
        "            y = yy[..., t:t + step]\n",
        "            im = model(xx)\n",
        "            loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
        "\n",
        "            if t == 0:\n",
        "                pred = im\n",
        "            else:\n",
        "                pred = torch.cat((pred, im), -1)\n",
        "\n",
        "            xx = torch.cat((xx[..., step:], im), dim=-1)\n",
        "\n",
        "        train_l2_step += loss.item()\n",
        "        l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n",
        "        train_l2_full += l2_full.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    test_l2_step = 0\n",
        "    test_l2_full = 0\n",
        "    with torch.no_grad():\n",
        "        for xx, yy in test_loader:\n",
        "            loss = 0\n",
        "            xx = xx.to(device)\n",
        "            yy = yy.to(device)\n",
        "\n",
        "            for t in range(0, T, step):\n",
        "                y = yy[..., t:t + step]\n",
        "                im = model(xx)\n",
        "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = im\n",
        "                else:\n",
        "                    pred = torch.cat((pred, im), -1)\n",
        "\n",
        "                xx = torch.cat((xx[..., step:], im), dim=-1)\n",
        "\n",
        "            test_l2_step += loss.item()\n",
        "            test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n",
        "\n",
        "    t2 = default_timer()\n",
        "    #scheduler.step()\n",
        "    print(ep, t2 - t1, train_l2_step / ntrain / (T / step), train_l2_full / ntrain, test_l2_step / ntest / (T / step),\n",
        "          test_l2_full / ntest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# old model"
      ],
      "metadata": {
        "id": "AWi4YHHASt8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 2 # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(9, self.width)\n",
        "        #self.fc1 = nn.Linear(self.width, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv4 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w4 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn4 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        #x = F.gelu(x)\n",
        "        #x = self.fc1(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn0(x))\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn1(x))\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x + self.bn2(x))\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "        #x = F.gelu(x + self.bn3(x))\n",
        "\n",
        "        #x1 = self.conv4(x)\n",
        "        #x2 = self.w4(x)\n",
        "        #x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
      ],
      "metadata": {
        "id": "6Mwm_r5KSvSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = FNO2d(12, 26, width=12).cuda()\n",
        "#model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
        "\n",
        "step = 1\n",
        "\n",
        "#print(count_params(model))\n",
        "optimizer = torch.optim.Adam(model.parameters(),  weight_decay=1e-4)#lr=learning_rate,\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "T =5\n",
        "epochs=10\n",
        "myloss = LpLoss(size_average=False)\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2_step = 0\n",
        "    train_l2_full = 0\n",
        "    for u,v,adt,U,V in train_dataloader:\n",
        "        batch = u.shape[0]\n",
        "        loss = 0\n",
        "        u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "        batch = u.shape[0]\n",
        "        expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "\n",
        "        for t in range(0, T, step):\n",
        "            y = U[..., t:t + step]\n",
        "            im = model(u)\n",
        "            loss += myloss(im.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "            if t == 0:\n",
        "                pred = im\n",
        "            else:\n",
        "                pred = torch.cat((pred, im), -1)\n",
        "\n",
        "            u = torch.cat((u[..., step:], im), dim=-1)\n",
        "\n",
        "        train_l2_step += loss.item()\n",
        "        l2_full = myloss(pred.reshape(batch, -1), U.reshape(batch, -1))\n",
        "        train_l2_full += l2_full.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    test_l2_step = 0\n",
        "    test_l2_full = 0\n",
        "    with torch.no_grad():\n",
        "      for u,v,adt,U,V in test_dataloader:\n",
        "            batch = u.shape[0]\n",
        "            loss = 0\n",
        "            u,v,adt,U,V = u.to(device),v.to(device),adt.to(device),U.to(device),V.to(device)\n",
        "            batch = u.shape[0]\n",
        "            expanded_mask_transformed = expanded_mask.expand(batch,91,195,10)\n",
        "\n",
        "            for t in range(0, T, step):\n",
        "                y = U[..., t:t + step]\n",
        "                im = model(u)\n",
        "                loss += myloss(im.reshape(batch, -1), y.reshape(batch, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = im\n",
        "                else:\n",
        "                    pred = torch.cat((pred, im), -1)\n",
        "\n",
        "                u = torch.cat((u[..., step:], im), dim=-1)\n",
        "\n",
        "            test_l2_step += loss.item()\n",
        "            test_l2_full += myloss(pred.reshape(batch, -1), U.reshape(batch, -1)).item()\n",
        "\n",
        "    t2 = default_timer()\n",
        "    #scheduler.step()\n",
        "    print(ep, t2 - t1, train_l2_step / ntrain / (T / step), train_l2_full / ntrain, test_l2_step / ntest / (T / step),\n",
        "          test_l2_full / ntest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwm4ziHLTMcl",
        "outputId": "2be4116e-457b-41c0-c5f2-1480f4de3cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 29.84318319500005 0.7987605598152911 0.8019161778674792 0.639203975967701 0.6413881022595791\n",
            "1 29.687642931000028 0.5756646609797358 0.5798975682640513 0.5486671024675658 0.55637944564155\n",
            "2 29.771238920000087 0.5007129398581638 0.5092223466397423 0.5091259188874941 0.5203944069873729\n",
            "3 29.658647115000008 0.4660390725561355 0.4771020481188183 0.48820785352879986 0.5026171670716143\n",
            "4 29.747233139999935 0.44365785280136005 0.4559961972574893 0.4687129856357871 0.4853065761265462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = len(train_data[0])\n",
        "\n",
        "ntest = len(test_data[0])\n"
      ],
      "metadata": {
        "id": "ypTaHIkgXk_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "gHRpilyQ4_KV",
        "zCyMoRtTldwS",
        "h0nyti9c3BCl"
      ],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}